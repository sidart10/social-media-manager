# Learn Voice Workflow Instructions (Enhanced v2.0)

<workflow>
<critical>This workflow MUST complete before write-posts or write-scripts can generate authentic content</critical>
<critical>Prioritize FREE tools (user's own APIs) over paid tools</critical>
<critical>v2.0 captures RHETORICAL DNA, not just surface patterns</critical>

<step n="1" goal="Gather user's profile URLs">
  <ask>I'll analyze your writing to capture your authentic voice - not just patterns, but your rhetorical DNA!

Please provide your profile URLs (need at least 1, ideally 2-3):

1. Twitter: Your @handle or profile URL
2. LinkedIn: Your profile URL
3. YouTube: Your channel URL (I'll analyze your spoken voice too)

Optional: URL to a writer whose style you'd like to blend (e.g., debarghyadas.com)

Note: I need at least {min_posts_required} posts total for accurate analysis. For deep rhetorical DNA extraction, 50+ posts recommended.

Provide URLs (one per line or comma-separated):
</ask>

<action>Parse provided URLs</action>
<action>Extract platforms and handles</action>
<action>Store: {platforms_provided}, {handles}, {reference_voice_url}</action>

<template-output>profiles_collected</template-output>
</step>

<step n="2" goal="Fetch YOUR content (cost-optimized)">
  <action>Display: "Fetching your content using free APIs where possible..."</action>

  <!-- TWITTER - Use built-in Twitter scraper if available -->
  <check if="twitter_handle provided">
    <action>Display: "üì± Twitter: Fetching your posts..."</action>

    <!-- Use apidojo/twitter-scraper-lite (verified, reliable) -->
    <action>Display: "Using Apify Twitter Scraper Lite (FREE tier available)"</action>
    <action>Use Apify: apidojo/twitter-scraper-lite</action>
    <action>Parameters:
      - twitterHandles: ["{handle}"]
      - maxItems: 100
      - sort: "Latest"
    </action>

    <action>Store tweets for analysis</action>
    <action>Display: "‚úì Fetched {tweet_count} tweets"</action>
    <action>Log cost: ~$0.02-0.04</action>

  </check>

  <!-- LINKEDIN - Use verified NO COOKIES scraper -->
  <check if="linkedin_url provided">
    <action>Display: "üíº LinkedIn: Fetching your posts..."</action>

    <action>Extract username from LinkedIn URL (e.g., /in/siddani/ ‚Üí siddani)</action>
    <action>Use Apify: datadoping/linkedin-profile-posts-scraper ‚úÖ VERIFIED</action>
    <action>Parameters:
      - profiles: ["{linkedin_username}"]
      - max_posts: 50  // minimum 10, get 50 for good sample
    </action>

    <action>Store posts for analysis</action>
    <action>Display: "‚úì Fetched {post_count} LinkedIn posts"</action>
    <action>Log cost: ~$0.06 (50 posts √ó $1.20/1000)</action>

  </check>

  <!-- YOUTUBE - Use FREE verified transcript extractor -->
  <check if="youtube_channel or youtube_video provided">
    <action>Display: "üé• YouTube: Fetching video transcripts..."</action>

    <action>Use Apify: dz_omar/youtube-transcript-metadata-extractor ‚úÖ VERIFIED</action>
    <action>Parameters:
      - youtubeUrl: [{"url": "{video_url}"}]  // Analyze 1-3 videos for speaking voice
      - cleaningLevel: "mild"
      - includeTimestamps: true
    </action>

    <action>Store transcripts for analysis</action>
    <action>Display: "‚úì Fetched transcripts from {video_count} YouTube videos"</action>
    <action>Log cost: FREE (platform fee ~$0.009 per video)</action>

    <note>YouTube transcripts analyze your SPOKEN voice:
      - Speaking rhythm and pace (words per minute)
      - Natural transitions ("but", "however", "so")
      - Teaching patterns (step-by-step vs story-driven)
      - Conversational markers ("um", "you know", "so", "right?")
      - Filler words and verbal tics
      - Pacing variations

      This helps adapt scripts to match how you actually speak!
    </note>

  </check>

  <!-- REFERENCE VOICE (Optional blend) -->
  <check if="reference_voice_url provided">
    <action>Display: "üé® Fetching reference voice for blending..."</action>

    <action>Use WebFetch or Exa to extract writing samples from reference URL</action>
    <action>Target: 20-30 representative samples</action>
    <action>Store reference samples separately</action>
    <action>Display: "‚úì Reference voice samples collected"</action>

  </check>

<action>Total posts collected: {total_posts}</action>

  <check if="total_posts < min_posts_required">
    <ask>‚ö†Ô∏è  Only collected {total_posts} posts. Need {min_posts_required}+ for accurate rhetorical DNA analysis.

    Options:
    1. Continue anyway (lower confidence score)
    2. Provide more profile URLs
    3. Reduce min_posts_required threshold

    Select: [1/2/3]
    </ask>

  </check>

<template-output>content_collected</template-output>
</step>

<step n="2.5" goal="Filter for authentic content (NEW v2.0)">
  <action>Display: "Filtering for your authentic writing (removing AI-generated content)..."</action>

<action>**AI-Generated Content Detection:** - Check timestamps: Recent posts (last 2 weeks) might be AI-generated - Analyze style consistency: Sudden pattern changes indicate AI - User confirmation: Ask user to confirm which recent posts are theirs
</action>

  <ask if="recent_posts_detected">
I found {recent_post_count} posts from the last 2 weeks. Some might be AI-generated (by me or other tools).

Recent posts:
{#recent_posts}

- "{post_preview_50_chars}" ({date})
  {/recent_posts}

Which of these did YOU actually write? (Enter numbers, e.g., "1,3,5" or "all" or "none"):
</ask>

<action>Filter out AI-generated content based on user response</action>
<action>Separate posts by length: - Short (< 150 chars): Casual voice candidates - Medium (150-500 chars): Mixed voice - Long (> 500 chars): Deep analysis candidates
</action>

<action>Display: "‚úì Filtered to {authentic_post_count} authentic posts"</action>
<action>Display: " - Short: {short_count} | Medium: {medium_count} | Long: {long_count}"</action>

<template-output>authentic_content_filtered</template-output>
</step>

<step n="3" goal="Surface Pattern Analysis (LEGACY - Keep)">
  <action>Display: "Running surface pattern analysis..."</action>

<action>**1. Vocabulary Analysis:**

- Count technical terms (AI, API, LLM, model, inference, context, eval, etc.)
- Calculate complexity: simple (< 10%), moderate (10-30%), advanced (> 30%)
- Map jargon vs accessible ratio
- Create word frequency map (top 50 words)
- Note specialized vocabulary clusters
  </action>

<action>**2. Sentence Structure Analysis:**

- Calculate average sentence length (words)
- Distribution:
  ‚Ä¢ Short (< 10 words): X%
  ‚Ä¢ Medium (10-20 words): Y%
  ‚Ä¢ Long (> 20 words): Z%
- Identify rhythm pattern:
  ‚Ä¢ Staccato: > 50% short sentences
  ‚Ä¢ Flowing: > 50% long sentences
  ‚Ä¢ Varied: Mixed distribution (most engaging)
- Track sentence complexity (simple/compound/complex)
  </action>

<action>**3. Tone Marker Extraction:**

- Formality indicators:
  ‚Ä¢ Formal: "Furthermore", "Utilize", "Accordingly"
  ‚Ä¢ Casual: "Plus", "Use", "So"
- Enthusiasm markers:
  ‚Ä¢ Exclamation points per post
  ‚Ä¢ Energetic words: "amazing", "excited", "energizing"
  ‚Ä¢ Superlatives: "most", "best", "biggest"
- Personal vs analytical:
  ‚Ä¢ First-person: "I think", "I believe", "I'm"
  ‚Ä¢ Third-person: "Research shows", "Studies indicate"
- Calculate tone score: 1-10 (1=very formal, 10=very casual)
  </action>

<action>**4. Signature Phrase Extraction:**

- Find phrases used 3+ times across all posts
- Common transitions:
  ‚Ä¢ "here's the thing"
  ‚Ä¢ "don't get me wrong"
  ‚Ä¢ "it seems like"
  ‚Ä¢ "what sets this apart"
- Opening patterns (first sentence analysis)
- Closing patterns (last sentence analysis)
- Filler patterns: "actually", "basically", "literally"
- Create ranked list by frequency
  </action>

<action>**5. Emoji Usage Analysis:**

- Count emoji frequency per post:
  ‚Ä¢ Never: 0 emojis
  ‚Ä¢ Rare: < 0.5 per post
  ‚Ä¢ Moderate: 1-2 per post
  ‚Ä¢ Heavy: 3+ per post
- Placement pattern: beginning|middle|end|scattered
- Type preferences:
  ‚Ä¢ Professional: üìäüìàüíº
  ‚Ä¢ Energy: ‚ö°Ô∏èüöÄüí°
  ‚Ä¢ Playful: üéâüòäüëç
- Single vs multiple emoji per post
- Functional vs decorative usage
  </action>

<action>**6. Hook Preference Identification:**

- Categorize opening lines of user's posts:
  ‚Ä¢ Question hooks: "What did it miss?"
  ‚Ä¢ Number hooks: "5 reasons why..."
  ‚Ä¢ Story hooks: "Last week, I..."
  ‚Ä¢ Statement hooks: "Anthropic is the most confident company"
  ‚Ä¢ Bold declaration: "AI stopped being software"
- Calculate distribution percentages
- Identify natural tendency (most frequent type)
  </action>

<template-output>surface_patterns_complete</template-output>
</step>

<step n="4" goal="Rhetorical DNA Analysis (NEW v2.0)">
  <action>Display: "Extracting rhetorical DNA - this is where your essence lives..."</action>

<action>**DIMENSION 1: Argument Architecture**

Analyze HOW user builds arguments (structure, not just content):

**Multi-Act Detection:**

- **Act 1 (Opening):** Thesis, question, or story?
  ‚Ä¢ Count: Thesis openings (bold declarations)
  ‚Ä¢ Count: Question openings
  ‚Ä¢ Count: Story/anecdote openings
  ‚Ä¢ Identify most common

- **Act 2 (Qualification):** Presence of hedges/acknowledgments
  ‚Ä¢ Search for: "don't get me wrong", "it seems like", "I believe"
  ‚Ä¢ Frequency: Never | Rare | Common | Always
  ‚Ä¢ Purpose: Shows intellectual honesty vs absolutism

- **Act 3 (Proof):** How user supports claims
  ‚Ä¢ Framework-driven: Numbered lists, eras, phases
  ‚Ä¢ Data-driven: Statistics, percentages, multipliers
  ‚Ä¢ Example-driven: Specific instances, case studies
  ‚Ä¢ Enumeration: Lists items exhaustively (Gmail, Notion, GitHub)
  ‚Ä¢ Identify dominant proof style

- **Act 4 (Closing):** How user ends posts
  ‚Ä¢ Reframed thesis: Returns to opening with new insight
  ‚Ä¢ Action CTA: "Let's get to work"
  ‚Ä¢ Question: Leaves reader thinking
  ‚Ä¢ Forward-looking: "The future is..."
  ‚Ä¢ Calculate distribution

**Output:** Argument architecture formula (e.g., "Bold thesis ‚Üí Qualification ‚Üí Framework proof ‚Üí Action close")
</action>

<action>**DIMENSION 2: Voice Mode Detection**

Identify distinct voice modes based on content type, length, and topic:

**Classification Criteria:**

- Post length (chars)
- Capitalization pattern (proper vs lowercase)
- Topic type (tech analysis vs personal vs community)
- Structural complexity
- Emotional tone

**Detect Modes:**

**Mode 1: Analyst**

- Triggers: Long posts (> 500 chars) about tech/product analysis
- Capitalization: Proper
- Structure: Framework-driven, numbered lists
- Proof: Enumerated features, named companies
- Energy: Confident but qualified
- Count posts matching this pattern

**Mode 2: Casual**

- Triggers: Short posts (< 150 chars), quick observations
- Capitalization: Often lowercase
- Structure: Simple observation, minimal setup
- Proof: Direct experience, no elaborate evidence
- Energy: Conversational, insider
- Count posts matching this pattern

**Mode 3: Community Protector**

- Triggers: Immigration, scams, community issues
- Capitalization: Proper
- Structure: Personal experience ‚Üí Frustration ‚Üí Action steps
- Proof: Personal data ("I receive X calls"), community sources
- Energy: Protective, emotional, actionable
- Count posts matching this pattern

**Mode 4: Satirist**

- Triggers: Calling out hype, exposing absurdity
- Capitalization: Proper (makes satire subtle)
- Structure: Over-the-top praise ‚Üí Escalating absurdity ‚Üí Deadpan close
- Proof: Hyperbolic claims as fact
- Energy: Deadpan, trusts reader intelligence
- Count posts matching this pattern

**Mode 5: Enthusiast**

- Triggers: Product launches, announcements, milestones
- Capitalization: Proper
- Structure: Build momentum ‚Üí Peak excitement ‚Üí Action CTA
- Proof: Specific tools/features listed
- Energy: High, genuine, infectious
- Count posts matching this pattern

**Mode Distribution:**

- Calculate % for each mode
- Identify default mode (most frequent)
- Create decision tree: When to use which mode

**Output:** Voice mode map with triggers and switching rules
</action>

<action>**DIMENSION 3: Structural Frameworks**

Extract frameworks user uses to organize complex information:

**Framework Types:**

- **Eras/Phases Framework:**
  ‚Ä¢ Search for: "Era of", "Phase 1", numbered evolution
  ‚Ä¢ Example: "1. Era of Turing test, 2. Era of reasoning, 3. Agents"
  ‚Ä¢ Frequency: Never | Rare | Common

- **Comparative Structure:**
  ‚Ä¢ Search for: "X vs Y", "while X does Y, Z does W"
  ‚Ä¢ Example: "Google uses TPUs, everyone else tied to NVIDIA"
  ‚Ä¢ Frequency and pattern

- **Numbered Lists:**
  ‚Ä¢ Count posts with 1, 2, 3... structure
  ‚Ä¢ Purpose: Action steps | Proof points | Features
  ‚Ä¢ Usage percentage

- **"What Sets This Apart" Differentiators:**
  ‚Ä¢ Search for: "what sets this apart", "differentiator", "unique"
  ‚Ä¢ Frequency: How often user identifies competitive advantage
  ‚Ä¢ Pattern: Always explains why X is different from Y

**Output:** Framework preference hierarchy
</action>

<action>**DIMENSION 4: Proof Style Analysis**

Analyze HOW user backs up claims:

**Specificity Ratio:**

- Count named entities (companies, tools, people) vs generic terms
  ‚Ä¢ Named: "Gmail, Notion, GitHub, Google Sheets"
  ‚Ä¢ Generic: "various tools", "many platforms"
- Calculate ratio: Named / Total mentions
- High ratio (> 80%) = Specificity obsession
- Low ratio (< 40%) = Abstract thinker

**Personal Experience Frequency:**

- Count first-person proof markers:
  ‚Ä¢ "I am using", "I receive", "I've found"
- Percentage of posts with personal experience
- When user uses personal vs impersonal proof

**Data Citation Patterns:**

- Count posts with:
  ‚Ä¢ Numbers: "10 months", "$315B", "8x increase"
  ‚Ä¢ Percentages: "80% growth", "16% drop"
  ‚Ä¢ Multipliers: "20x", "10x"
- Data density: Numbers per 100 words
- Precision level: Exact vs approximate

**Enumeration vs Summarization:**

- Does user list every item or summarize?
  ‚Ä¢ Enumerator: "Amazon, Microsoft, Google, Meta" (lists all 4)
  ‚Ä¢ Summarizer: "Big 4 tech companies" (summarizes)
- Calculate enumeration preference percentage

**Output:** Proof style formula (e.g., "High specificity, personal experience, data-heavy, enumeration preferred")
</action>

<action>**DIMENSION 5: Humor & Satire Mechanics**

Detect humor patterns and satirical techniques:

**Satire Detection:**

- Search for hyperbolic language:
  ‚Ä¢ "perfect", "100%", "completely shattered", "end of development"
- Escalating absurdity patterns:
  ‚Ä¢ "gold standard, platinum standard, whatever-is-better-than-gold"
- Deadpan closers:
  ‚Ä¢ "Pack it up, folks", "thanks for playing"
- Count satirical posts vs total
- Calculate satire frequency

**Humor Type:**

- Deadpan vs Explicit:
  ‚Ä¢ Deadpan: No LOL, no wink emoji, trust reader
  ‚Ä¢ Explicit: Clear humor markers
- Irony vs Sarcasm vs Wit
- Self-deprecation presence

**Humor Topics:**

- When does user deploy humor?
  ‚Ä¢ Hype cycles (DeepSeek satire)
  ‚Ä¢ Industry culture
  ‚Ä¢ Tech trends
- When does user stay serious?
  ‚Ä¢ Community protection
  ‚Ä¢ Career milestones
  ‚Ä¢ Technical analysis

**Output:** Humor profile (frequency, type, topics, delivery style)
</action>

<action>**DIMENSION 6: Emotional Range Mapping**

Map emotional expression patterns:

**Enthusiasm Markers:**

- Amplifying language:
  ‚Ä¢ "most energizing thing I can imagine"
  ‚Ä¢ "best thing I can do"
  ‚Ä¢ "most exciting yet"
- Exclamation points (frequency and placement)
- Energy emojis (‚ö°Ô∏è) at closings
- Calculate enthusiasm intensity by post type

**Frustration/Disappointment Markers:**

- Moral clarity language:
  ‚Ä¢ "deeply disappointing"
  ‚Ä¢ "unfortunate", "frustrating"
- When frustration appears (community issues, scams)
- How user expresses frustration (direct vs implicit)

**Qualification/Hedging Markers:**

- "Don't get me wrong"
- "It seems like"
- "I believe" vs "This is"
- Shows intellectual humility
- Frequency across posts

**Protective Language:**

- Community warnings: "Heads-up, everyone"
- Empowerment closings: "help stop the cycle"
- Collective pronouns: "we", "us", "our community"
- When user adopts protector role

**Output:** Emotional range profile with triggers for each emotion type
</action>

<action>**DIMENSION 7: Closing Mechanics**

Analyze how user ends posts (critical for energy and CTA):

**CTA Types:**

- **Action CTAs:**
  ‚Ä¢ "Let's get to work. ‚ö°Ô∏è"
  ‚Ä¢ "Let's build"
  ‚Ä¢ Calculate frequency

- **Question CTAs:**
  ‚Ä¢ "I'd love to hear your thoughts"
  ‚Ä¢ "How do you see this transforming..."
  ‚Ä¢ Calculate frequency

- **Forward-Looking Statements:**
  ‚Ä¢ "The possibilities are immense"
  ‚Ä¢ "The future is being shaped here"
  ‚Ä¢ "every chapter keeps getting better"
  ‚Ä¢ Calculate frequency

- **Empowerment Closings:**
  ‚Ä¢ "help stop the cycle"
  ‚Ä¢ Community action encouragement

**Energy Punctuation:**

- ‚ö°Ô∏è placement and frequency
- Single emoji as punctuation vs decoration
- When user uses energy markers vs when they don't

**Closing Formula:**

- Most common closing type
- Platform variations (LinkedIn vs Twitter closings)
- Content-type variations (analysis vs announcement)

**Output:** Closing playbook by content type
</action>

<action>**DIMENSION 8: Parenthetical Analysis**

Analyze use of parentheses and asides:

**Frequency:**

- Count parentheticals per post
- Distribution: Never | Rare (< 1 per post) | Common (1-2) | Heavy (3+)

**Content Type in Parentheses:**

- Technical details:
  ‚Ä¢ "(often relying heavily on platforms like ComfyUI)"
- Examples:
  ‚Ä¢ "(e.g., @siddani09)"
- Qualifications:
  ‚Ä¢ "(don't get me wrong)"
- Asides:
  ‚Ä¢ "(this is wild)"
- Calculate what goes in parens most often

**Function:**

- Depth-adding: Provides technical detail without breaking flow
- Tangent: Side thought
- Qualifier: Hedges main claim
- Example: Concrete instance
- Identify primary function

**Output:** Parenthetical usage guide (when, what, how often)
</action>

<action>**DIMENSION 9: Cultural Voice & Code-Switching**

Detect cultural identity markers and bilingual elements:

**Community-Specific Language:**

- Immigration terminology: "F1, CPT, OPT, H1B, STEM"
- Indian tech diaspora references
- "fellow Indians", "immigrant community"
- Insider vs outsider framing

**Bilingual Elements:**

- Hindi/English mixing (if present)
- Cultural references
- When code-switching happens (topic-dependent?)

**Insider Perspective:**

- Does user speak AS immigrant or ABOUT immigration?
- Community protector voice activation
- "Heads-up, everyone" vs "They should..."

**Reference Voice Blending (if provided):**

- Extract similar patterns from reference voice
- Identify complementary elements to blend
- Note: Keep user's core voice, enhance with reference patterns

**Output:** Cultural voice markers and code-switching triggers
</action>

<action>**DIMENSION 10: Comparative Lens**

Analyze how user frames competitive/strategic analysis:

**X vs Y Comparison Frequency:**

- Count direct comparisons:
  ‚Ä¢ "Google uses TPUs, everyone else uses NVIDIA"
  ‚Ä¢ "Anthropic vs other labs"
- Calculate comparison density (comparisons per 100 words)

**Competitive Framing:**

- "What sets this apart" pattern frequency
- How user identifies differentiators
- Strategic advantage language:
  ‚Ä¢ "major differentiator", "unique strength", "cost advantage"

**Enumeration for Contrast:**

- Lists competitors individually:
  ‚Ä¢ "Amazon: 8x. Microsoft: 20x. Google: 15x. Meta: 20x."
- Never summarizes when can enumerate
- Shows mastery through exhaustive listing

**Strategic Thinking Markers:**

- Product thinking language
- Business model analysis
- Cost/pricing discussions
- Moat identification

**Output:** Comparative lens profile (how user analyzes competition)
</action>

<template-output>rhetorical_dna_extracted</template-output>
</step>

<step n="5" goal="Detect platform variations">
  <check if="multiple platforms provided">
    <action>Compare writing style across platforms</action>

    <action>**Twitter vs LinkedIn (if both available):**
      - Formality difference (tone score delta)
      - Length difference (avg words per post)
      - Emoji usage difference
      - Topic difference (professional vs personal)
      - Capitalization pattern (proper vs lowercase)
      - Voice mode distribution (which modes appear on which platform)
      - Note: "On LinkedIn, user is X% more formal and uses Analyst mode Y% more"
    </action>

    <action>**Written vs Spoken (if YouTube available):**
      - Vocabulary in videos vs posts
      - Sentence complexity difference
      - Conversational markers in videos ("um", "you know", "right?")
      - Teaching mode indicators
      - Explanation style (patient vs concise)
      - Note: "Spoken voice is more [casual/explanatory/energetic]"
    </action>

  </check>

  <check if="only one platform">
    <action>Note: "Single platform analyzed - voice profile based on {platform} only"</action>
    <action>Suggest: "For more accurate profile, provide LinkedIn/Twitter/YouTube URLs"</action>
  </check>

<template-output>platform_variations_detected</template-output>
</step>

<step n="6" goal="Build Enhanced Voice Profile (v2.0)">
  <action>Compile all findings into comprehensive voice DNA profile</action>

<action>**Enhanced Voice Profile Format (v2.0):**

# Voice Profile: {user_name} (Enhanced v2.0)

**Status:** Complete ‚úÖ
**Analyzed:** {date}
**Sources:** {platform_breakdown}
**Total Posts:** {total_posts} ({long_form_count} long-form, {casual_count} casual)
**Confidence Score:** {confidence}/10
(20-30 posts: 6/10, 30-50 posts: 7/10, 50-100 posts: 8/10, 100+ posts: 9/10)
**Version:** 2.0 (Rhetorical DNA Enabled)

---

## PART 1: Surface Patterns (Legacy Analysis)

**Vocabulary Level:** {vocab_level} (simple|moderate|advanced)

- Technical term density: {tech_term_pct}%
- Jargon vs Accessible: {jargon_ratio}
- Power words: {top_10_words}

**Sentence Structure:** {sentence_pattern} (staccato|flowing|varied)

- Average length: {avg_length} words
- Short (< 10): {short_pct}% | Medium (10-20): {med_pct}% | Long (> 20): {long_pct}%
- Rhythm: {rhythm_description}

**Tone Score:** {tone_score}/10 (1=formal, 10=casual)
**Overall Tone:** {tone_description}

**Emoji Usage:**

- Frequency: {emoji_freq} (never|rare|moderate|heavy)
- Placement: {emoji_placement}
- Types: {emoji_types}
- Function: {emoji_function} (punctuation|decoration|energy)

---

## PART 2: Rhetorical DNA (NEW - v2.0)

### Argument Architecture

**Your Formula:** {argument_formula}

**Multi-Act Structure:**

- **Act 1 (Opening):** {opening_type} ({opening_pct}% of posts)
  - Pattern: {opening_pattern_description}
  - Example: "{opening_example}"

- **Act 2 (Qualification):** {qualification_type}
  - Frequency: {qualification_freq}
  - Markers: {qualification_phrases}
  - Example: "{qualification_example}"

- **Act 3 (Proof):** {proof_type}
  - Style: {proof_style_description}
  - Tools: {proof_tools} (frameworks|data|enumeration|examples)
  - Example: "{proof_example}"

- **Act 4 (Closing):** {closing_type} ({closing_pct}% of posts)
  - Pattern: {closing_pattern_description}
  - Example: "{closing_example}"

---

### Voice Modes (Content-Based Switching)

**Mode Distribution:**

1. **{mode_1_name}:** {mode_1_pct}% of content
2. **{mode_2_name}:** {mode_2_pct}% of content
3. **{mode_3_name}:** {mode_3_pct}% of content
4. **{mode_4_name}:** {mode_4_pct}% of content
5. **{mode_5_name}:** {mode_5_pct}% of content

**Default Mode:** {default_mode} (most frequent)

---

#### Mode 1: {MODE_NAME_1}

**Triggers:**

- Content type: {trigger_content_1}
- Length: {trigger_length_1}
- Topic: {trigger_topic_1}

**Characteristics:**

- Capitalization: {cap_pattern_1}
- Structure: {structure_1}
- Proof style: {proof_1}
- Energy: {energy_1}
- Closing: {closing_1}

**Example:**
"{example_post_1}"

**When to Use:**
{usage_guide_1}

---

#### Mode 2: {MODE_NAME_2}

**Triggers:**

- Content type: {trigger_content_2}
- Length: {trigger_length_2}
- Topic: {trigger_topic_2}

**Characteristics:**

- Capitalization: {cap_pattern_2}
- Structure: {structure_2}
- Proof style: {proof_2}
- Energy: {energy_2}
- Closing: {closing_2}

**Example:**
"{example_post_2}"

**When to Use:**
{usage_guide_2}

---

#### Mode 3: {MODE_NAME_3}

**Triggers:**

- Content type: {trigger_content_3}
- Length: {trigger_length_3}
- Topic: {trigger_topic_3}

**Characteristics:**

- Capitalization: {cap_pattern_3}
- Structure: {structure_3}
- Proof style: {proof_3}
- Energy: {energy_3}
- Closing: {closing_3}

**Example:**
"{example_post_3}"

**When to Use:**
{usage_guide_3}

---

#### Mode 4: {MODE_NAME_4}

**Triggers:**

- Content type: {trigger_content_4}
- Length: {trigger_length_4}
- Topic: {trigger_topic_4}

**Characteristics:**

- Capitalization: {cap_pattern_4}
- Structure: {structure_4}
- Proof style: {proof_4}
- Energy: {energy_4}
- Closing: {closing_4}

**Example:**
"{example_post_4}"

**When to Use:**
{usage_guide_4}

---

#### Mode 5: {MODE_NAME_5}

**Triggers:**

- Content type: {trigger_content_5}
- Length: {trigger_length_5}
- Topic: {trigger_topic_5}

**Characteristics:**

- Capitalization: {cap_pattern_5}
- Structure: {structure_5}
- Proof style: {proof_5}
- Energy: {energy_5}
- Closing: {closing_5}

**Example:**
"{example_post_5}"

**When to Use:**
{usage_guide_5}

---

### Structural Frameworks

**Framework Preferences:**

1. **{framework_1}:** Used in {fw_1_pct}% of long posts
   - Example: "{fw_1_example}"
2. **{framework_2}:** Used in {fw_2_pct}% of long posts
   - Example: "{fw_2_example}"
3. **{framework_3}:** Used in {fw_3_pct}% of posts
   - Example: "{fw_3_example}"

**Primary Framework:** {primary_framework}

**"What Sets This Apart" Pattern:**

- Frequency: {differentiator_freq}
- Usage: {differentiator_usage_description}
- Example: "{differentiator_example}"

---

### Proof Style

**Specificity Obsession:** {specificity_ratio}% named entities vs generics

**Formula:**

- Named entities: {named_pct}% (Gmail, Notion, GitHub vs "various tools")
- Personal experience: {personal_exp_pct}% of posts
- Data citations: {data_citation_pct}% of posts
- Enumeration preference: {enumeration_pct}% (list all vs summarize)

**Proof Hierarchy:**

1. {proof_hierarchy_1}
2. {proof_hierarchy_2}
3. {proof_hierarchy_3}

**Data Style:**

- Precision: {data_precision} (exact|approximate)
- Density: {numbers_per_100_words} numbers per 100 words
- Types: {data_types} (percentages, multipliers, absolute numbers)

---

### Humor & Satire

**Humor Frequency:** {humor_freq} ({satirical_post_count}/{total_posts} posts)

**Type:** {humor_type}

- Deadpan satire: {deadpan_pct}%
- Ironic commentary: {irony_pct}%
- Self-deprecation: {selfdep_pct}%

**Satirical Technique:**

- Hyperbolic setup: "{hyperbole_example}"
- Escalating absurdity: "{escalation_example}"
- Deadpan delivery: No wink emoji, trust reader

**Humor Topics:**

- Appears when: {humor_triggers}
- Avoided when: {serious_topics}

---

### Emotional Range

**Enthusiasm Markers:**

- Frequency: {enthusiasm_freq}
- Amplifiers: {enthusiasm_amplifiers}
- Peak words: {peak_words} ("most exciting", "best thing")

**Frustration Expression:**

- Frequency: {frustration_freq}
- Markers: {frustration_markers}
- Triggers: {frustration_topics}

**Qualification/Hedging:**

- "Don't get me wrong": {hedge_1_count} times
- "It seems like": {hedge_2_count} times
- "I believe": {hedge_3_count} times
- Function: Shows intellectual honesty, not weakness

**Protective Language:**

- Community warnings: {protection_count} posts
- Empowerment closings: {empowerment_count} posts
- Collective voice: {collective_pct}%

---

### Closing Patterns

**CTA Distribution:**

- Action: {action_cta_pct}% ("Let's get to work. ‚ö°Ô∏è")
- Question: {question_cta_pct}% ("I'd love to hear your thoughts")
- Forward-looking: {forward_cta_pct}% ("The future is...")
- Empowerment: {empower_cta_pct}% ("help stop the cycle")

**Energy Markers:**

- ‚ö°Ô∏è usage: {energy_emoji_count}/{total_posts} posts
- Placement: {energy_placement} (always end, never middle)
- When used: {energy_triggers}

**Default Closing:** {default_closing_type}

---

### Parenthetical Usage

**Frequency:** {paren_freq} per post

**Content Types:**

- Technical details: {tech_detail_pct}%
- Examples: {example_pct}%
- Qualifications: {qual_pct}%
- Asides: {aside_pct}%

**Function:** {paren_function}

- Adds depth without density
- Preserves main claim accessibility
- Shows expertise in aside

**Example:**
"{paren_example}"

---

### Cultural Voice

**Community Identity:**

- Speaks AS: {speaks_as} (immigrant|insider|community member)
- Topics: {community_topics}
- Language: {community_language_markers}

**Bilingual Elements:**

- Frequency: {bilingual_freq}
- Type: {bilingual_type}
- Context: {bilingual_context}

**Insider Framing:**

- {insider_description}

---

### Comparative Lens

**Comparison Frequency:** {comparison_freq} comparisons per post

**Pattern:**

- Direct X vs Y: {direct_comparison_pct}%
- Implicit positioning: {implicit_comparison_pct}%
- Strategic differentiation: {differentiation_pct}%

**"What Sets Apart" Usage:**

- Frequency: {sets_apart_freq}
- Always identifies competitive advantage
- Never describes in isolation

**Formula:** {comparison_formula}

**Example:**
"{comparison_example}"

---

## PART 3: Signature Elements (Enhanced)

**Transition Phrases (Ranked by Frequency):**
{#top_transitions}

1. "{transition_phrase}" - {count} times
   {/top_transitions}

**Opening Patterns:**
{#opening_patterns}

- {pattern_type}: {pattern_pct}% - "{example}"
  {/opening_patterns}

**Closing Patterns:**
{#closing_patterns}

- {pattern_type}: {pattern_pct}% - "{example}"
  {/closing_patterns}

**Rhetorical Devices:**
{#rhetorical_devices}

- {device_name}: {frequency} - "{example}"
  {/rhetorical_devices}

---

## PART 4: Platform Variations

{#twitter}
**Twitter:**

- Tone: {twitter_tone}
- Length: {twitter_avg_words} words avg
- Capitalization: {twitter_cap_pattern}
- Dominant mode: {twitter_mode}
- Style notes: {twitter_style_notes}
  {/twitter}

{#linkedin}
**LinkedIn:**

- Tone: {linkedin_tone}
- Length: {linkedin_avg_words} words avg
- Capitalization: {linkedin_cap_pattern}
- Dominant mode: {linkedin_mode}
- Style notes: {linkedin_style_notes}
  {/linkedin}

{#youtube}
**YouTube (Spoken):**

- Delivery: {youtube_delivery}
- Teaching style: {teaching_approach}
- Conversational markers: {spoken_patterns}
- Pace: {speaking_pace}
- Dominant mode: {youtube_mode}
  {/youtube}

---

## PART 5: Voice Matching Guidelines (Enhanced)

### When writing as {user_name}, ALWAYS:

1. **{guideline_1_title}:** {guideline_1_description}
2. **{guideline_2_title}:** {guideline_2_description}
3. **{guideline_3_title}:** {guideline_3_description}
4. **{guideline_4_title}:** {guideline_4_description}
5. **{guideline_5_title}:** {guideline_5_description}
6. **{guideline_6_title}:** {guideline_6_description}
7. **{guideline_7_title}:** {guideline_7_description}
8. **{guideline_8_title}:** {guideline_8_description}

### DO:

{#do_patterns}

- {pattern}
  {/do_patterns}

### DON'T:

{#dont_patterns}

- {pattern}
  {/dont_patterns}

---

## PART 6: Mode Selection Decision Tree

**Content Type Decision Tree:**

```
Is it a quick observation/reaction?
‚îú‚îÄ YES ‚Üí Use CASUAL mode (lowercase, < 150 chars)
‚îî‚îÄ NO ‚Üí Continue...

Is it about tech/product analysis?
‚îú‚îÄ YES ‚Üí Use ANALYST mode (proper caps, frameworks, enumeration)
‚îî‚îÄ NO ‚Üí Continue...

Is it about community/immigration/scams?
‚îú‚îÄ YES ‚Üí Use COMMUNITY PROTECTOR mode (emotional honesty, action steps)
‚îî‚îÄ NO ‚Üí Continue...

Is it satirizing hype/calling out absurdity?
‚îú‚îÄ YES ‚Üí Use SATIRIST mode (hyperbole, escalation, deadpan)
‚îî‚îÄ NO ‚Üí Continue...

Is it an announcement/milestone/excitement?
‚îî‚îÄ YES ‚Üí Use ENTHUSIAST mode (momentum building, energy close)
```

---

## PART 7: Example Transformations

### Example 1: Tech Analysis

**Generic AI voice:**
"{generic_example_1}"

**{user_name}'s authentic voice:**
"{authentic_example_1}"

**Why different:**

- {reason_1_1}
- {reason_1_2}
- {reason_1_3}

---

### Example 2: Quick Take

**Generic AI voice:**
"{generic_example_2}"

**{user_name}'s authentic voice:**
"{authentic_example_2}"

**Why different:**

- {reason_2_1}
- {reason_2_2}

---

### Example 3: Community Post

**Generic AI voice:**
"{generic_example_3}"

**{user_name}'s authentic voice:**
"{authentic_example_3}"

**Why different:**

- {reason_3_1}
- {reason_3_2}
- {reason_3_3}

---

## PART 8: Reference Voice Integration (Optional)

{#reference_voice}
**Reference Writer:** {reference_name}
**Style Elements Blended:**
{#blended_elements}

- {element_name}: {element_description}
  {/blended_elements}

**Blending Strategy:**

- Keep core {user_name} voice: {core_elements}
- Enhance with {reference_name} patterns: {enhancement_elements}
- Avoid: {avoid_elements}

**Result:**
{user_name}'s authentic voice enhanced with {specific_blend_description}
{/reference_voice}

---

## PART 9: Quality Metrics

**Sample Size:** {total_posts} posts
**Content Diversity:** {platform_count} platforms, {mode_count} voice modes detected
**Analysis Depth:** {dimensions_analyzed}/16 dimensions analyzed
**Long-Form Posts:** {long_form_count} (need 5+ for deep analysis)
**Confidence:** {confidence}/10

{#confidence < 7}
‚ö†Ô∏è **Limited Sample Warning:**

- Need more posts for higher confidence
- Some patterns may not be statistically significant
- Run /learn-voice again after 50+ new posts
  {/confidence}

{#confidence >= 8}
‚úÖ **High Confidence:**

- Large sample size ({total_posts} posts)
- Multiple voice modes detected
- Clear rhetorical patterns identified
- Ready for authentic content generation
  {/confidence}

---

## PART 10: Content Generation Implications

**What This Unlocks:**

‚úÖ **/write-posts** - Posts that match your exact voice mode for each platform
‚úÖ **/write-scripts** - Scripts with your argument architecture and energy
‚úÖ **Mode-aware generation** - Automatically selects voice mode based on content type
‚úÖ **Rhetorical consistency** - Maintains your proof style and structural frameworks
‚úÖ **Authentic closings** - Uses your actual CTA patterns

**Voice-Aware Features:**

- Auto-detects when to use Analyst vs Casual mode
- Applies your qualification patterns ("don't get me wrong")
- Uses your proof hierarchy (specifics > generics)
- Maintains your closing energy formulas
- Preserves your emotional range

---

_Voice profile improves with more content. Run /learn-voice again after 50+ new posts._
_Last updated: {date}_
_Version: 2.0 (Rhetorical DNA)_

  </action>

<action>Save enhanced voice profile to memories.md (replace "Voice Profile" section)</action>
<action>Update voice_profile_status in memories.md: "complete_v2"</action>
<action>Update voice_profile_version: "2.0"</action>
<action>Update voice_profile_date: {date}</action>
<action>Update confidence_score: {confidence}</action>
<action>Add rhetorical_dna_enabled: true</action>

<template-output>voice_profile_enhanced_saved</template-output>
</step>

<step n="7" goal="Present results to user">
  <action>Display:

‚úÖ Voice Profile v2.0 Complete - Rhetorical DNA Captured!

**Analyzed:**

- {total_posts} posts across {platform_count} platforms
- {long_form_count} long-form posts for deep analysis
- {twitter_count} Twitter + {linkedin_count} LinkedIn + {youtube_count} YouTube

**Your Writing DNA:**

- **Vocabulary:** {vocab_level} ({tech_term_pct}% technical)
- **Tone:** {tone_description} ({tone_score}/10)
- **Sentence rhythm:** {sentence_pattern}
- **Argument structure:** {argument_formula}
- **Proof style:** {proof_style_summary}
- **Dominant voice mode:** {default_mode}

**Voice Modes Detected:**
{#voice_modes}

- {mode_name}: {mode_pct}% of content
  {/voice_modes}

**Rhetorical Signature:**

- Opening: {opening_signature}
- Qualification: {qualification_signature}
- Closing: {closing_signature}

**Confidence:** {confidence}/10
{#confidence < 7}
‚ö†Ô∏è Based on limited sample ({total_posts} posts). Profile will improve with more content.
{/confidence}

{#confidence >= 8}
‚úÖ High confidence - {total_posts} posts analyzed across multiple modes.
{/confidence}

**NEW in v2.0:**
‚úÖ Voice mode detection (5 modes identified)
‚úÖ Argument architecture mapping
‚úÖ Rhetorical DNA extraction
‚úÖ Proof style analysis
‚úÖ Humor mechanics captured
‚úÖ Emotional range profiled
‚úÖ Mode-specific templates generated

üìÑ Full Enhanced Profile: Saved to memories.md (Voice Profile section)

**What This Unlocks:**
‚úÖ /write-posts - Automatically selects correct voice mode
‚úÖ /write-scripts - Matches your argument architecture
‚úÖ Mode-aware generation - Casual vs Analyst vs Satirist
‚úÖ Authentic closings - Your actual CTA patterns
‚úÖ Rhetorical consistency - Maintains your proof style

**Next Steps:**

- Test enhanced voice with /write-posts or /write-scripts
- Voice mode will auto-select based on content type
- Re-run /learn-voice after 50+ new posts to refine

**Cost for this analysis:** ${total_cost}

  </action>

<template-output>workflow_complete</template-output>
</step>

</workflow>
