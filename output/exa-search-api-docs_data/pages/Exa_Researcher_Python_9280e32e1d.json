{
  "title": "Exa Researcher - Python",
  "content": "Source: https://docs.exa.ai/examples/exa-researcher-python\n\n## What this doc covers\n\n1. Using Exa's Auto search to pick the best search setting for each query (keyword or neural)\n2. Using search\\_and\\_contents() through Exa's Python SDK\n\nIn this example, we will build Exa Researcher, a Python app that, given a research topic, automatically searches for relevant sources with Exa's [auto search](../reference/how-exa-search-works#auto-search-combines-keyword-and-neural) and synthesizes the information into a reliable research report.\n\nTo run this code, first we need a [Exa API key](https://dashboard.exa.ai/api-keys) and an [OpenAI API key](https://platform.openai.com/api-keys).\n\nIf you would like to se the full code for this tutorial as a Colab notebook, [click here](https://colab.research.google.com/drive/1Aj6bBptSHWxZO7GVG2RoWtQSEkpabuaF?usp=sharing)\n\nLet's import the Exa and OpenAI SDKs and set up our API keys to create client objects for each. We'll use environment variables to securely store our API keys.\n\nSince we'll be making several calls to the OpenAI API to get a completion from GPT-3.5 Turbo, let's make a simple utility function so we can pass in the system and user messages directly, and get the LLM's response back as a string.\n\nOkay, great! Now let's start building Exa Researcher.\n\nThe researcher should be able to automatically generate research reports for all kinds of different topics. Here's two to start:\n\nThe first thing our researcher has to do is decide what kind of search to do for the given topic.\n\nExa offers two kinds of search: **neural** and **keyword** search. Here's how we decide:\n\n* Neural search is preferred when the query is broad and complex because it lets us retrieve high quality, semantically relevant data. Neural search is especially suitable when a topic is well-known and popularly discussed on the Internet, allowing the machine learning model to retrieve contents which are more likely recommended by real humans.\n* Keyword search is useful when the topic is specific, local or obscure. If the query is a specific person's name, and identifier, or acronym, such that relevant results will contain the query itself, keyword search may do well. And if the machine learning model doesn't know about the topic, but relevant documents can be found by directly matching the search query, keyword search may be necessary.\n\nConveniently, Exa's [auto search](../reference/how-exa-search-works#auto-search-combines-keyword-and-neural) feature (on by default) will automatically decide whether to use `keyword` or `neural` search for each query. For example, if a query is a specific person's name, Exa would decide to use keyword search.\n\nNow, we'll create a helper function to generate search queries for our topic.\n\nNext, let's write another function that actually calls the Exa API to perform searches using Auto search.\n\n## Writing a report with GPT-3.5 Turbo\n\nThe final step is to instruct the LLM to synthesize the content into a research report, including citations of the original links. We can do that by pairing the content and the URLs and writing them into the prompt.\n\nNow, let's just wrap everything into one Researcher function that strings together all the functions we've written. Given a user's research topic, the Researcher will generate search queries, feed those queries to Exa Auto search, and finally use an LLM to synthesize the retrieved information. Three simple steps!\n\nIn just a couple lines of code, we've used Exa to go from a research topic to a valuable essay with up-to-date sources.\n\n```Python Python theme={null}\ndef run_examples():\n    print(\"Researching Sam Altman:\")\n    sama_report = researcher(SAMA_TOPIC)\n    print(sama_report)\n\nprint(\"\\n\\nResearching Renaissance Art:\")\n    art_report = researcher(ART_TOPIC)\n    print(art_report)",
  "code_samples": [
    {
      "code": "Since we'll be making several calls to the OpenAI API to get a completion from GPT-3.5 Turbo, let's make a simple utility function so we can pass in the system and user messages directly, and get the LLM's response back as a string.",
      "language": "unknown"
    },
    {
      "code": "Okay, great! Now let's start building Exa Researcher.\n\n## Exa Auto search\n\nThe researcher should be able to automatically generate research reports for all kinds of different topics. Here's two to start:",
      "language": "unknown"
    },
    {
      "code": "The first thing our researcher has to do is decide what kind of search to do for the given topic.\n\nExa offers two kinds of search: **neural** and **keyword** search. Here's how we decide:\n\n* Neural search is preferred when the query is broad and complex because it lets us retrieve high quality, semantically relevant data. Neural search is especially suitable when a topic is well-known and popularly discussed on the Internet, allowing the machine learning model to retrieve contents which are more likely recommended by real humans.\n* Keyword search is useful when the topic is specific, local or obscure. If the query is a specific person's name, and identifier, or acronym, such that relevant results will contain the query itself, keyword search may do well. And if the machine learning model doesn't know about the topic, but relevant documents can be found by directly matching the search query, keyword search may be necessary.\n\nConveniently, Exa's [auto search](../reference/how-exa-search-works#auto-search-combines-keyword-and-neural) feature (on by default) will automatically decide whether to use `keyword` or `neural` search for each query. For example, if a query is a specific person's name, Exa would decide to use keyword search.\n\nNow, we'll create a helper function to generate search queries for our topic.",
      "language": "unknown"
    },
    {
      "code": "Next, let's write another function that actually calls the Exa API to perform searches using Auto search.",
      "language": "unknown"
    },
    {
      "code": "## Writing a report with GPT-3.5 Turbo\n\nThe final step is to instruct the LLM to synthesize the content into a research report, including citations of the original links. We can do that by pairing the content and the URLs and writing them into the prompt.",
      "language": "unknown"
    },
    {
      "code": "## All Together Now\n\nNow, let's just wrap everything into one Researcher function that strings together all the functions we've written. Given a user's research topic, the Researcher will generate search queries, feed those queries to Exa Auto search, and finally use an LLM to synthesize the retrieved information. Three simple steps!",
      "language": "unknown"
    },
    {
      "code": "In just a couple lines of code, we've used Exa to go from a research topic to a valuable essay with up-to-date sources.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "What this doc covers",
      "id": "what-this-doc-covers"
    },
    {
      "level": "h2",
      "text": "Setup",
      "id": "setup"
    },
    {
      "level": "h2",
      "text": "Exa Auto search",
      "id": "exa-auto-search"
    },
    {
      "level": "h2",
      "text": "Writing a report with GPT-3.5 Turbo",
      "id": "writing-a-report-with-gpt-3.5-turbo"
    },
    {
      "level": "h2",
      "text": "All Together Now",
      "id": "all-together-now"
    }
  ],
  "url": "llms-txt#exa-researcher---python",
  "links": []
}