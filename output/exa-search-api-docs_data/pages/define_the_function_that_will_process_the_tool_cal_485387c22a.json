{
  "title": "define the function that will process the tool call and perform the exa search",
  "content": "def process_tool_calls(tool_calls, messages):\n    \n    for tool_call in tool_calls:\n        function_name = tool_call.function.name\n        function_args = json.loads(tool_call.function.arguments)\n        \n        if function_name == \"exa_search\":\n            search_results = exa_search(**function_args)\n            messages.append(\n                {\n                    \"role\": \"tool\",\n                    \"content\": str(search_results),\n                    \"tool_call_id\": tool_call.id,\n                }\n            )\n            console.print(\n                f\"[bold cyan]Context updated[/bold cyan] [i]with[/i] \"\n                f\"[bold green]exa_search ({function_args.get('mode')})[/bold green]: \",\n                function_args.get(\"query\"),\n            )\n            \n    return messages\n\ndef main():\n    messages = [SYSTEM_MESSAGE]\n    \n    while True:\n        try:\n            # create the user input prompt using rich\n            user_query = Prompt.ask(\n                \"[bold yellow]What do you want to search for?[/bold yellow]\",\n            )\n            messages.append({\"role\": \"user\", \"content\": user_query})\n            \n            # call openai llm by creating a completion which calls the defined exa tool\n            completion = openai.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=messages,\n                tools=TOOLS,\n                tool_choice=\"auto\",\n            )\n            \n            # completion will contain the object needed to invoke your tool and perform the search\n            message = completion.choices[0].message\n            tool_calls = message.tool_calls\n            \n            if tool_calls:\n\nmessages.append(message)\n\n# process the tool object created by OpenAI llm and store the search results\n                messages = process_tool_calls(tool_calls, messages)\n                messages.append(\n                    {\n                        \"role\": \"user\",\n                        \"content\": \"Answer my previous query based on the search results.\",\n                    }\n                )\n                \n                # call OpenAI llm again to process the search results and yield the final answer\n                completion = openai.chat.completions.create(\n                    model=\"gpt-4o\",\n                    messages=messages,\n                )\n                \n                # parse the agents final answer and print it\n                console.print(Markdown(completion.choices[0].message.content))\n            else:\n                console.print(Markdown(message.content))\n        except Exception as e:\n            console.print(f\"[bold red]An error occurred:[/bold red] {str(e)}\")\n            \n            \nif __name__ == \"__main__\":\n    main()\n```",
  "code_samples": [],
  "headings": [],
  "url": "llms-txt#define-the-function-that-will-process-the-tool-call-and-perform-the-exa-search",
  "links": []
}