{
  "title": "Answer",
  "content": "Source: https://docs.exa.ai/reference/answer\n\npost /answer\nGet an LLM answer to a question informed by Exa search results. `/answer` performs an Exa search and uses an LLM to generate either:\n1. A direct answer for specific queries. (i.e. \"What is the capital of France?\" would return \"Paris\")\n2. A detailed summary with citations for open-ended queries (i.e. \"What is the state of ai in healthcare?\" would return a summary with citations to relevant sources)\n\nThe response includes both the generated answer and the sources used to create it. The endpoint also supports streaming (as `stream=True`), which will return tokens as they are generated.\n\nAlternatively, you can use the OpenAI compatible [chat completions interface](https://docs.exa.ai/reference/chat-completions#answer).\n\n<Card title=\"Get your Exa API key\" icon=\"key\" horizontal href=\"https://dashboard.exa.ai/api-keys\" />",
  "code_samples": [],
  "headings": [],
  "url": "llms-txt#answer",
  "links": []
}