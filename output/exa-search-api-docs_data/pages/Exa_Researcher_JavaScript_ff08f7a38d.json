{
  "title": "Exa Researcher - JavaScript",
  "content": "Source: https://docs.exa.ai/examples/exa-researcher\n\nExample project using the Exa JS SDK.\n\n## What this doc covers\n\n1. Using Exa's Auto search to pick the best search setting for each query (keyword or neural)\n2. Using searchAndContents() through Exa's JavaScript SDK\n\nIn this example, we will build Exa Researcher, a JavaScript app that, given a research topic, automatically searches for relevant sources with Exa's [**Auto search**](/changelog/auto-search-as-default) and synthesizes the information into a reliable research report.\n\nFastest setup: Interact with the code in your browser with this Replit [template](https://replit.com/@olafblitz/exa-researcher?v=1).\n\nAlternatively, this [interactive notebook](https://github.com/exa-labs/exa-js/tree/master/examples/researcher/researcher.ipynb) was made with the Deno Javascript kernel for Jupyter so you can easily run it locally. Check out the [plain JS version](https://github.com/exa-labs/exa-js/tree/master/examples/researcher/researcher.mjs) if you prefer a regular Javascript file you can run with NodeJS, or want to skip to the final result. If you'd like to run this notebook locally, [Installing Deno](https://docs.deno.com/runtime/manual/getting%5Fstarted/installation) and [connecting Deno to Jupyter](https://docs.deno.com/runtime/manual/tools/jupyter) is fast and easy.\n\nTo play with this code, first we need a [Exa API key](https://dashboard.exa.ai/api-keys) and an [OpenAI API key](https://platform.openai.com/api-keys).\n\nLet's import the Exa and OpenAI SDKs and put in our API keys to create a client object for each. Make sure to pick the right imports for your runtime and paste or load your API keys.\n\nSince we'll be making several calls to the OpenAI API to get a completion from GPT-3.5 Turbo, let's make a simple utility function so we can pass in the system and user messages directly, and get the LLM's response back as a string.\n\nOkay, great! Now let's starting building Exa Researcher.\n\nThe researcher should be able to automatically generate research reports for all kinds of different topics. Here's two to start:\n\nThe first thing our researcher has to do is decide what kind of search to do for the given topic.\n\nExa offers two kinds of search: **neural** and **keyword** search. Here's how we decide:\n\n* Neural search is preferred when the query is broad and complex because it lets us retrieve high quality, semantically relevant data. Neural search is especially suitable when a topic is well-known and popularly discussed on the Internet, allowing the machine learning model to retrieve contents which are more likely recommended by real humans.\n* Keyword search is useful when the topic is specific, local or obscure. If the query is a specific person's name, and identifier, or acronym, such that relevant results will contain the query itself, keyword search may do well. And if the machine learning model doesn't know about the topic, but relevant documents can be found by directly matching the search query, keyword search may be necessary.\n\nConveniently, Exa's autosearch feature (on by default) will automatically decide whether to use `keyword` or `neural` search for each query. For example, if a query is a specific person's name, Exa would decide to use keyword search.\n\nNow, we'll create a helper function to generate search queries for our topic.\n\nNext, let's write another function that actually calls the Exa API to perform searches using Auto search.\n\n## Writing a report with GPT-4\n\nThe final step is to instruct the LLM to synthesize the content into a research report, including citations of the original links. We can do that by pairing the content and the URLs and writing them into the prompt.\n\nNow, let's just wrap everything into one Researcher function that strings together all the functions we've written. Given a user's research topic, the Researcher will generate search queries, feed those queries to Exa Auto search, and finally use an LLM to synthesize the retrieved information. Three simple steps!\n\nIn just a couple lines of code, we've used Exa to go from a research topic to a valuable essay with up-to-date sources.\n\nFor a link to a complete, cleaned up version of this project that you can execute in your NodeJS environment, check out the [alternative JS-only version](https://github.com/exa-labs/exa-js/tree/master/examples/researcher/researcher.mjs).",
  "code_samples": [
    {
      "code": "Since we'll be making several calls to the OpenAI API to get a completion from GPT-3.5 Turbo, let's make a simple utility function so we can pass in the system and user messages directly, and get the LLM's response back as a string.",
      "language": "unknown"
    },
    {
      "code": "Okay, great! Now let's starting building Exa Researcher.\n\n## Exa Auto search\n\nThe researcher should be able to automatically generate research reports for all kinds of different topics. Here's two to start:",
      "language": "unknown"
    },
    {
      "code": "The first thing our researcher has to do is decide what kind of search to do for the given topic.\n\nExa offers two kinds of search: **neural** and **keyword** search. Here's how we decide:\n\n* Neural search is preferred when the query is broad and complex because it lets us retrieve high quality, semantically relevant data. Neural search is especially suitable when a topic is well-known and popularly discussed on the Internet, allowing the machine learning model to retrieve contents which are more likely recommended by real humans.\n* Keyword search is useful when the topic is specific, local or obscure. If the query is a specific person's name, and identifier, or acronym, such that relevant results will contain the query itself, keyword search may do well. And if the machine learning model doesn't know about the topic, but relevant documents can be found by directly matching the search query, keyword search may be necessary.\n\nConveniently, Exa's autosearch feature (on by default) will automatically decide whether to use `keyword` or `neural` search for each query. For example, if a query is a specific person's name, Exa would decide to use keyword search.\n\nNow, we'll create a helper function to generate search queries for our topic.",
      "language": "unknown"
    },
    {
      "code": "Next, let's write another function that actually calls the Exa API to perform searches using Auto search.",
      "language": "unknown"
    },
    {
      "code": "## Writing a report with GPT-4\n\nThe final step is to instruct the LLM to synthesize the content into a research report, including citations of the original links. We can do that by pairing the content and the URLs and writing them into the prompt.",
      "language": "unknown"
    },
    {
      "code": "## All Together Now\n\nNow, let's just wrap everything into one Researcher function that strings together all the functions we've written. Given a user's research topic, the Researcher will generate search queries, feed those queries to Exa Auto search, and finally use an LLM to synthesize the retrieved information. Three simple steps!",
      "language": "unknown"
    },
    {
      "code": "In just a couple lines of code, we've used Exa to go from a research topic to a valuable essay with up-to-date sources.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "What this doc covers",
      "id": "what-this-doc-covers"
    },
    {
      "level": "h2",
      "text": "Setup",
      "id": "setup"
    },
    {
      "level": "h2",
      "text": "Exa Auto search",
      "id": "exa-auto-search"
    },
    {
      "level": "h2",
      "text": "Writing a report with GPT-4",
      "id": "writing-a-report-with-gpt-4"
    },
    {
      "level": "h2",
      "text": "All Together Now",
      "id": "all-together-now"
    }
  ],
  "url": "llms-txt#exa-researcher---javascript",
  "links": []
}