{
  "title": "RAG Q&A",
  "content": "Source: https://docs.exa.ai/examples/exa-rag\n\nUsing Exa to enable retrieval-augmented generation.\n\n### What this doc covers\n\n1. Using Exa search\\_and\\_contents to find relevant webpages for a query and get their contents\n2. Performing Exa search based on text similarity rather than a search query\n\nThe Jupyter notebook for this tutorial is available on [Colab](https://colab.research.google.com/drive/1iXfXg9%5F-MEmhwW1a0WRHHbMl21jSxjO7?usp=sharing) for easy experimentation.\n\n## Answer your questions with context\n\nLLMs are powerful because they compress large amounts of data into a format that allows convenient access, but this compressions isn't lossless. LLMs are prone to hallucination, corrupting facts and details from training data.\n\nTo get around this fundamental issue with LLM reliability, we can use Exa to bring the most relevant data into contextâ€”a fancy way of saying: put the info in the LLM prompt directly. This lets us combine the compressed data and *reasoning abilities* of the LLM with a curated selection of uncompressed, accurate data for the problem at hand for the best answers possible.\n\nExa's SDKs make incorporating quality data into your LLM pipelines quick and painless. Install the SDK by running this command in your terminal:\n\n```Python Python theme={null}",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h3",
      "text": "What this doc covers",
      "id": "what-this-doc-covers"
    },
    {
      "level": "h2",
      "text": "Answer your questions with context",
      "id": "answer-your-questions-with-context"
    }
  ],
  "url": "llms-txt#rag-q&a",
  "links": []
}